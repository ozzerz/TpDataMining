{
  "comments": [
    "I somewhat clicked my way around in the task list, then this error happened.\nConnected\nto a Jira repository.\nShouldnt be that hard to find...\n\n\nI report this through the Mylar\ninterface, the version 1.0.0 does not appear in the Attributes/Version list.\n\n\nMylar Version\n1.0.0 \nJira Connector 1.0.0\n\nBRgds\nAndreas \n\n-- Error Log --\nDate: Mon Dec 11 10:32:13\nCET 2006\nMessage: An internal error occurred during: \"Task List Saver\".\nSeverity: Error\nPlugin\nID: org.eclipse.core.jobs\nStack Trace:\njava.util.ConcurrentModificationException\nat java.util.HashMap$HashIterator.nextEntry(HashMap.java:787)\nat\njava.util.HashMap$KeyIterator.next(HashMap.java:823)\nat java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1010)\nat\norg.eclipse.mylar.internal.tasks.ui.util.TaskListWriter.writeTaskList(TaskListWriter.java:120)\nat\norg.eclipse.mylar.internal.tasks.ui.util.TaskListSaveManager.internalSaveTaskList(TaskListSaveManager.java:131)\nat\norg.eclipse.mylar.internal.tasks.ui.util.TaskListSaveManager.access$0(TaskListSaveManager.java:129)\nat\norg.eclipse.mylar.internal.tasks.ui.util.TaskListSaveManager$TaskListSaverJob.run(TaskListSaveManager.java:306)\nat\norg.eclipse.core.internal.jobs.Worker.run(Worker.java:58)",
    "Yes, on rare occasion we can reproduce this in our test suite.  There should be no bad behavior, since the next Task List save will succeed and they happen on every modification.  If there was any bad behavior please let us know.",
    "Related to bug#165745?",
    "Yes, partly.  What happened is that Eugnen\u0027s enhancement to make the Task List saves asynchronous (bug 166607) can sometimes trigger thread safety problems with Task List and the way that we externalize it (in this  case the list is modified while it is being written).  Previously we relied on the lack of synchronous modify and write, and I applied that patch too late in the 1.0 end game for us to recover entirely from this change (it introduced other race conditions that we had to recover from).  So for 1.0 we have the benefit of faster saves, but introduced this concurrency problem.  As I said we were aware of it before releasing and it won\u0027t cause any bad behavior.  The worst part about it right now is that it will cause the test suite to fail every so often, so I\u0027m scheduling it for 1.0.1.",
    "(In reply to comment #3)\nMik, in a retrospective, do you think it was a bad idea to apply my patch?\n\nBy the way, we should probably always return a copy of any children collection instead of wrapping that collection on the callee side...",
    "\u003e (In reply to comment #3)\n\u003e Mik, in a retrospective, do you think it was a bad idea to apply my patch?\n\nIt\u0027s a real borderline case, it probably was a mistake, but not because of what your patch did (other than the fact that you should have run AllTests to catch some of the errors sooner).  The mistake was for me to apply it know that we probably didn\u0027t have enough time to recover fully from implementation bugs that your patch could have uncovered, since performance optimizations of this sort tend to be uncover bugs of that sort.  That said, other than the problem of the test suite regression, the net effect of us having applied your patch is a positive one for Mylar users since this bug is totally minor, and the reduction in Task List writing will be noticeable on slow machines or with very large Task Lists.\n\n\u003e By the way, we should probably always return a copy of any children collection\n\u003e instead of wrapping that collection on the callee side...\n\nYes, as part of doing some fixes bug 165745 I made all relevant collections return unmodifiable lists, so we\u0027ll actually get the exception that we want to see.  But the bug here is access to a map while it is changing.",
    "(In reply to comment #5)\n\u003e That said, other than the problem of the\n\u003e test suite regression, the net effect of us having applied your patch is a\n\u003e positive one for Mylar users since this bug is totally minor, and the reduction\n\u003e in Task List writing will be noticeable on slow machines or with very large\n\u003e Task Lists.\n\nActually patch was addressing issues with group operations. Those operations were incredibly slow even on fast machines, because time for those operations was linear function from the number of affected tasks, with fixed time on writing task list. So, schedule, delete, mark read, etc executed on 100 tasks were required 100 * time need to write task list (1..3 seconds for me).\n\n\u003e \u003e By the way, we should probably always return a copy of any children collection\n\u003e \u003e instead of wrapping that collection on the callee side...\n\u003e \n\u003e Yes, as part of doing some fixes bug 165745 I made all relevant collections\n\u003e return unmodifiable lists, so we\u0027ll actually get the exception that we want to\n\u003e see.  But the bug here is access to a map while it is changing.\n\nNO. Unmodifiable lists does not help. We should return an explicit copy instead. I was also thinking about using CopyOnWriteArrayList, but it has stupid limitation that defeat the benefits of using it.",
    "Just had this same error happen in my workspace. No adverse effects to report yet...but we need to get this resolved.",
    " (In reply to comment #6)\n\u003e NO. Unmodifiable lists does not help. We should return an explicit copy instead.\n\u003e I was also thinking about using CopyOnWriteArrayList, but it has stupid\n\u003e limitation that defeat the benefits of using it.\n\nCopyOnWriteArrayList must be used only on situations where modifications are rare.\n\nJust return an explicit copy won\u0027t fix the problem too, because a concurrent operation can happen while copying the internal collection.\n\nWe need to protected all modifying operations + collection getters from TaskList either using synchronize or using lightweight Locks (this is the preferred/optimized way).",
    "BTW, Mik, what was implemented for bug#165745? I just checked TaskList class and there is not concurrency handling.",
    "(In reply to comment #8)\n\u003e CopyOnWriteArrayList must be used only on situations where modifications are\n\u003e rare.\n\nRight. But do we know how often write is happening comparing to iteration?\n\nThe limitation I was referring to is that copy on write collection could take into account that copy should only happens after iterator instance had been requested. If there was no new iterator instance since last write most likely there is no need to copy list.\n\n\u003e Just return an explicit copy won\u0027t fix the problem too, because a concurrent\n\u003e operation can happen while copying the internal collection.\n\nSure, the copying method need to be synchronized.\n\n\u003e We need to protected all modifying operations + collection getters from\n\u003e TaskList either using synchronize or using lightweight Locks (this is the\n\u003e preferred/optimized way).\n\nHmm. What do you call lightweight locks? Isn\u0027t hotspot optimizing synchonized blocks already?",
    "(In reply to comment #10)\n\u003e Right. But do we know how often write is happening comparing to iteration?\n\nHumm... Every time a task or query is added to tasklist?\n\n\u003e Hmm. What do you call lightweight locks? Isn\u0027t hotspot optimizing synchonized\n\u003e blocks already?\n\u003e \n\nYes, Sun is making a lot of optimizations on synchronized blocks on each release of hotspot.\n\nThe lightweight lock I was referring to is the Lock interface and its ReentrantLock implementation, which is semantically equivalent to a synchronized block, but it is more flexible and efficient, however it adds more complexity.",
    "(In reply to comment #11)\n\u003e \u003e Right. But do we know how often write is happening comparing to iteration?\n\u003e Humm... Every time a task or query is added to tasklist?\n\nSo, that isn\u0027t really as often as iteration which is currently happens on any change of attributes of these tasks.\n\n\u003e The lightweight lock I was referring to is the Lock interface and its\n\u003e ReentrantLock implementation, which is semantically equivalent to a\n\u003e synchronized block, but it is more flexible and efficient, however it adds more\n\u003e complexity.\n\nMy impression was that these locks only needed if you need to do lock/unlock between method calls. Otherwise there should be more space for optimization when locking is isolated within one method...",
    "(In reply to comment #12)\n\u003e So, that isn\u0027t really as often as iteration which is currently happens on any\n\u003e change of attributes of these tasks.\n\nI think we need to examine each case. E.g., copying the entire task list on each add operation in a huge tasklist would be very bad.\n\nHowever, for query/category lists it would perform well.\n\nBut all of this introduce a new degree of complexity. Perhaps just synchronize would be fine to us.\n\n\u003e My impression was that these locks only needed if you need to do lock/unlock\n\u003e between method calls. Otherwise there should be more space for optimization\n\u003e when locking is isolated within one method...\n\u003e \n\nYes it is only a matter of optimization. There is a trade-off between complexity and optimization.",
    "Willian, Eugene: I haven\u0027t been able to take a close look yet, have you converged on a proposal for handling this concurrency?",
    "Created an attachment (id\u003d55620)\nprototype patch for concurrency issues\n\nI think that current anteraction nature is mostly iteration. So, we should use CopyOnWriteArrayList/CopyOnWriteArraySet and ConcurrentHashMap for all collections.\n\nThis patch replaces collections directly involved into task list data structures, but I could of missed something. Also, I haven\u0027t wrapped collections returned from these classes into the unmodifiable wrappers...",
    "Created an attachment (id\u003d55621)\nmylar/context/zip\n\n",
    "Mik, please note that I haven\u0027t really tested this patch. It is more to outline the idea...",
    "-1 about the CopyOnWrite-collections and simply use the ConcurrentHashMap.\n\n1 - I think CopyOnWrite collections would be an overkill for this situation. It will turn each add operation expensive. If I\u0027m not wrong, CopyOnWrite are only for situations where changes are rare and read operations many times more frequent, so the price of not using any synchronization/concurrent collection is very worth. On this case we don\u0027t have data to justify it.\n\n2 - About the ConcurrentCollections, I\u0027m afraid to use them, because they can mask some concurrency bug, i.e., there are methods that touches the internal task list AND the internal category list. I wonder if there can be some situation when another process touch one of the structures. On this case, I think the better is to synchronize the whole block (or method).\n\nBut all of this are just speculation. I hadn\u0027t analyzed all possible scenarios.",
    "Created an attachment (id\u003d55841)\nProposal patch using synchronized\n\nLike Eugene said, this is only to outline my idea too :)\n\nI\u0027m not sure if it is secure to apply this type of change for 1.0.1.",
    "Created an attachment (id\u003d55842)\nmylar/context/zip\n\n",
    "(In reply to comment #18)\n\u003e -1 about the CopyOnWrite-collections and simply use the ConcurrentHashMap.\n\nThere is no concurrent hash map for ordered collections, so copy on write is the only option besides synchronization. Note that you\u0027ll have to synchronize/block on entire iteration cycle trough collection elements. And that is much worse then create the copy.\n\n\u003e 1 - I think CopyOnWrite collections would be an overkill for this situation. \n\nIf I recall correctly there are some copy-on-read happening already. So, my proposal should only make things better. :-)\n\n\u003e It will turn each add operation expensive. If I\u0027m not wrong, CopyOnWrite are only\n\u003e for situations where changes are rare and read operations many times more\n\u003e frequent, so the price of not using any synchronization/concurrent collection\n\u003e is very worth. On this case we don\u0027t have data to justify it.\n\nThat is the thing. Tasks and hits aren\u0027t added that often. So, we do have case for copy on write.\n\n\u003e 2 - About the ConcurrentCollections, I\u0027m afraid to use them, because they can\n\u003e mask some concurrency bug, i.e., there are methods that touches the internal\n\u003e task list AND the internal category list. I wonder if there can be some\n\u003e situation when another process touch one of the structures. On this case, I\n\u003e think the better is to synchronize the whole block (or method).\n\nIt won\u0027t be any worse. The idea is that concurrent collections give you a slice of time. So, if things are added afterwards, they will be all processed at the next iteration.",
    "(In reply to comment #21)\n\u003e If I recall correctly there are some copy-on-read happening already. So, my\n\u003e proposal should only make things better. :-)\n\n*sigh* :)\n\nI think the CopyOnRead case can (must?) be optimized in future by analyzing each case; e.g., move the method that is iterating into the tasklist and synchronized it...\n\n\u003e That is the thing. Tasks and hits aren\u0027t added that often. So, we do have case\n\u003e for copy on write.\n\nHumm... no? :-)\n\nhttp://www.jroller.com/page/eu?entry\u003dmylar_has_turned_one\n\nI presume there are at least 400+ (based on your estimative of 1 bug/day) bugs on your tasklist. Every time you add one, or open some new query hit, it will create a new arraylist and copy all elements into it.\n\nIt is not a scalable solution... like I said, the CopyOnWrite are for rare changes.\n\n\u003e It won\u0027t be any worse. The idea is that concurrent collections give you a slice\n\u003e of time. So, if things are added afterwards, they will be all processed at the\n\u003e next iteration.\n\u003e \n\nLike I said, I hadn\u0027t analyzed all use cases, so that is why I\u0027m afraid on simply turning the internal collections on concurrent collections.",
    "(In reply to comment #22)\n\u003e I think the CopyOnRead case can (must?) be optimized in future by analyzing\n\u003e each case; e.g., move the method that is iterating into the tasklist and\n\u003e synchronized it...\n\nI doubt you can move any iteration block into the task list, unless you are willing to use command/closure pattern, which is less natural to code around.\n\n\u003e \u003e That is the thing. Tasks and hits aren\u0027t added that often. So, we do have case\n\u003e \u003e for copy on write.\n\u003e I presume there are at least 400+ (based on your estimative of 1 bug/day) bugs\n\u003e on your tasklist. Every time you add one, or open some new query hit, it will\n\u003e create a new arraylist and copy all elements into it.\n\nYou know what they say about statistics? Believe it or not, but 1 task a day added is nothing comparing to hundreds of times task list is being iterated trough.\n\n\u003e It is not a scalable solution... like I said, the CopyOnWrite are for rare\n\u003e changes.\n\nAren\u0027t those rare enough? Do you want it to be added not more often then once a year or what?",
    "*** Bug 167308 has been marked as a duplicate of this bug. ***",
    "Willian, Eugene: thanks for the analysis and dialog.  For 1.0.1 I have tried to pick the least disruptive path, and so what I have done is made the four stores of task list data be ConcurrentHashMap\u0027s.  All were either sets or maps so this was a straightforward change.  I believe that for this case the concurrent collections actually give us the expected behavior that Eugene describes: when you iterate over the TaskList, you get the collection that corresponds to the \"slice of time\" that you asked for it in (i.e. additions made while you are iterating will be ignored).\n\nThe only testing that I have done of this is to run the AllTasksTests suite 10x in a row.  Previously a few runs would reliably cause a concurrency problem, and I can no longer reproduce.\n\nEugene: on today\u0027s conference call you mentioned looking for places that made copies of task list contents, and that this should no longer be necessary.  Were those places in your patch, or did you mean that we should look through the existing accessors of some of the methods?",
    "(In reply to comment #25)\n\u003e The only testing that I have done of this is to run the AllTasksTests suite 10x\n\u003e in a row.  Previously a few runs would reliably cause a concurrency problem,\n\u003e and I can no longer reproduce.\n\nCool stuff!\n\n\u003e Eugene: on today\u0027s conference call you mentioned looking for places that made\n\u003e copies of task list contents, and that this should no longer be necessary. \n\u003e Were those places in your patch, or did you mean that we should look through\n\u003e the existing accessors of some of the methods?\n\nNo. Those wasn\u0027t included into my patch. For example in TaskListWriter has : new ArrayList\u003cITask\u003e(taskList.getAllTasks())\n\nYou may also want to look at the type of AbstractRepositoryQuery.hitHandles field and other collections in the ITaskListElement object hierarchy\n\nAlso, there is no need to wrap value set returned from concurrent hash map like you did in TaskList.getQueryHits() and few other methods. That set will have same semantics as the originating map.",
    "Thanks for all your input on this guys, it really helped.  Ironic how the solution was so simple in the end, but I\u0027m really glad that thanks to your analysis we now have a good understanding of the options and tradeoffs.  We should still keep an eye out for any concurrency problems since we do not currently have a direct test for this.\n\nEugene, regarding those wrapped value sets, yes, they don\u0027t do anything, but I had to temporarily add them because ConcurrentHashMap.values() returns a Collection, and our current API says we return a Set.  I\u0027ve added TODOs to remove that once we can change the API post 1.0.1.\n\n    // TODO: remove wrapping once API can change\n    return Collections.unmodifiableSet(new HashSet\u003cAbstractRepositoryQuery\u003e(queries.values()));\n    \nI searched for all access of these 4 maps, and the only non-test class I found still copying was TaskListWriter, and I removed that copy.",
    "Created an attachment (id\u003d56013)\nmylar/context/zip\n\n",
    "Mik, how about AbstractRepositoryQuery and AbstractTaskContainer classes? Maybe there is few others in this hierarchy. Those also may have same concurrency issues for their children...",
    "Yes, that had crossed my mind, but we can\u0027t do it in a reasonable way without changing that API to return Collection\u003cITask\u003e instead of a set.  We should have always had it return a Collection going by Bloch\u0027s API guidelines of using the most top-level interface you can, because that would have made this change possible.  For post 1.0.1 I have created bug 168878.\n\nI just saw a very odd, albeit minor, problem: I deactivate a task via Ctrl+Shift+F9 and it did deactivate, but the Task List still showed it as active.  I thought I had seen something like this a week or two ago.  Will investigate, and if anyone alse sees something like this please comment.",
    "(In reply to comment #30)\n\u003e I just saw a very odd, albeit minor, problem: I deactivate a task via\n\u003e Ctrl+Shift+F9 and it did deactivate, but the Task List still showed it as\n\u003e active.  I thought I had seen something like this a week or two ago.  Will\n\u003e investigate, and if anyone alse sees something like this please comment.\n\nI think I found the problem: we\u0027re using a List for all active tasks, and clients were using that bogus idiom of making copies of the list to avoid concurrency.  What I have done instead is made TaskList.activeTasks a CopyOnWriteArrayList as per Eugene\u0027s suggestion.  With the current UI this list only has 0 or 1 items in it, s othere is no performance issue.",
    " (In reply to comment #30)\n\u003e Yes, that had crossed my mind, but we can\u0027t do it in a reasonable way without\n\u003e changing that API to return Collection\u003cITask\u003e instead of a set.  We should have\n\u003e always had it return a Collection going by Bloch\u0027s API guidelines of using the\n\u003e most top-level interface you can, because that would have made this change\n\u003e possible.  For post 1.0.1 I have created bug 168878.\n\nYes, but for sets you can actually use ConcurrentHashMap with single bogus instance as a value. Then map.keySet() will give you instance of the concurrent set.\n\nSame applies to TaskList.tasks, TaskList.categories and TaskList.queries collections. Collection TaskList.queryHits seem to actually need get by key operation...\n\nAlso note this bogus copy in TaskList class:\n\n\tpublic void refactorRepositoryUrl(Object oldUrl, String newUrl) {\n\t\tfor (ITask task : new ArrayList\u003cITask\u003e(tasks.values())) {\n\nand this strange code in getQueryHits() method (it should not call queryHits.get(handle) twice):\n\n\t\t\tAbstractQueryHit hit \u003d queryHits.get(handle);\n\t\t\tif(hit !\u003d null) {\n\t\t\t\tresult.add(queryHits.get(handle));\n\t\t\t}\n\n",
    "Fixed both cases.",
    "(In reply to comment #33)\n\u003e Fixed both cases.\n\nWhat about ConcurrentHashMap fields?\n",
    "We can do that post 1.0.1 as part of bug 168878, please comment there if you haven\u0027t yet.",
    "(In reply to comment #35)\n\u003e We can do that post 1.0.1 as part of bug 168878, please comment there if you\n\u003e haven\u0027t yet.\n\nI did. But change I suggesting does not require API changes.\n\n",
    "I know, but I need to put attention on other bugs and am not sure if I have time to do that for 1.0.1."
  ],
  "commentCreationDates": [
    "2006-12-11T10:43:37+01:00",
    "2006-12-11T15:54:13+01:00",
    "2006-12-11T18:53:27+01:00",
    "2006-12-11T21:14:50+01:00",
    "2006-12-11T21:24:08+01:00",
    "2006-12-11T21:41:56+01:00",
    "2006-12-11T22:03:10+01:00",
    "2006-12-12T19:32:36+01:00",
    "2006-12-13T02:41:30+01:00",
    "2006-12-13T02:47:01+01:00",
    "2006-12-13T03:52:32+01:00",
    "2006-12-13T04:15:20+01:00",
    "2006-12-13T04:58:07+01:00",
    "2006-12-13T14:31:44+01:00",
    "2006-12-13T17:31:57+01:00",
    "2006-12-13T23:19:53+01:00",
    "2006-12-13T23:20:02+01:00",
    "2006-12-14T22:10:08+01:00",
    "2006-12-18T03:23:44+01:00",
    "2006-12-18T03:28:58+01:00",
    "2006-12-18T03:29:02+01:00",
    "2006-12-18T03:37:12+01:00",
    "2006-12-18T03:59:10+01:00",
    "2006-12-18T04:07:24+01:00",
    "2006-12-19T03:02:00+01:00",
    "2006-12-19T23:19:53+01:00",
    "2006-12-19T23:39:10+01:00",
    "2006-12-21T00:14:11+01:00",
    "2006-12-21T00:14:15+01:00",
    "2006-12-21T02:43:00+01:00",
    "2006-12-21T18:04:19+01:00",
    "2006-12-21T18:17:39+01:00",
    "2006-12-21T19:31:11+01:00",
    "2006-12-22T20:32:43+01:00",
    "2006-12-22T20:35:01+01:00",
    "2006-12-22T20:40:54+01:00",
    "2006-12-22T20:42:41+01:00",
    "2006-12-22T21:00:31+01:00"
  ],
  "traces": [
    {
      "exceptionType": "java.util.ConcurrentModificationException",
      "elements": [
        {
          "method": "java.util.HashMap$HashIterator.nextEntry",
          "source": "HashMap.java:787"
        },
        {
          "method": "java.util.HashMap$KeyIterator.next",
          "source": "HashMap.java:823"
        },
        {
          "method": "java.util.Collections$UnmodifiableCollection$1.next",
          "source": "Collections.java:1010"
        },
        {
          "method": "org.eclipse.mylar.internal.tasks.ui.util.TaskListWriter.writeTaskList",
          "source": "TaskListWriter.java:120"
        },
        {
          "method": "org.eclipse.mylar.internal.tasks.ui.util.TaskListSaveManager.internalSaveTaskList",
          "source": "TaskListSaveManager.java:131"
        },
        {
          "method": "org.eclipse.mylar.internal.tasks.ui.util.TaskListSaveManager.access$0",
          "source": "TaskListSaveManager.java:129"
        },
        {
          "method": "org.eclipse.mylar.internal.tasks.ui.util.TaskListSaveManager$TaskListSaverJob.run",
          "source": "TaskListSaveManager.java:306"
        },
        {
          "method": "org.eclipse.core.internal.jobs.Worker.run",
          "source": "Worker.java:58"
        }
      ],
      "number": 0,
      "commentIndex": 0,
      "bugId": "167402",
      "date": "2006-12-11T10:43:37+01:00",
      "product": "Mylyn",
      "component": "Bugzilla",
      "severity": "minor"
    }
  ],
  "groupId": "167402",
  "bugId": "167402",
  "date": "2006-12-11T10:43:37+01:00",
  "product": "Mylyn",
  "component": "Bugzilla",
  "severity": "minor"
}