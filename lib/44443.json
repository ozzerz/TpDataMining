{
  "comments": [
    "Each time a change occurs in the Problems View, the filtering mechanism is \ncalled too often (3 times at least).  Each time getElements() is called, all \nthe problem markers are retrieved and the filters applied to the whole list.  \nThis happens even for updating the title of the view (to tell you how many \nitems are in the view).  This is causing serious performance degradation if \nthere are many problem markers in total (i.e. about 1000 problems).  \n\nSee also:\nbug 44069 - [Problems View] Time response while debugging slows down when \nseveral perspectives are opened\nbug 39436 - [Tasks] No summary shown in status line\nbug 43721 - Performance regression on Mac",
    "*** Bug 42923 has been marked as a duplicate of this bug. ***",
    "Post M4, we (JDTCore) will explore removing the validation of compilation unit \nelement names (since 1.0). Need to be careful about ramifications, but should \nimprove performance significantly.",
    "Is there a bug report associated with the JDT work (so we will know when this \nwork has been complete)?",
    "I created one for this item, see bug 44662.",
    "*** Bug 44728 has been marked as a duplicate of this bug. ***",
    "FYI, a newsgroup user is reporting full builds in M3 taking \"forever\" (over an\nhour) when the problems view is filtering, while performance is fine when the\nfiltering is turned off.",
    "*** Bug 45168 has been marked as a duplicate of this bug. ***",
    "*** Bug 45164 has been marked as a duplicate of this bug. ***",
    "Created an attachment (id\u003d6661)\nBeginnings of a fix\n\nThis patch is not a complete fix.",
    "Created an attachment (id\u003d6722)\nThis builds on debbie\u0027s previous patch\n\nIn addition to debbie\u0027s previous patch:\n- Rather than computing all markers and filtering them, the filter critia is\nused to direct the search. Thus the filtering time is now proportional to the\nnumber of markers that pass the filter, not the total number of markers. This\nparticularly speeds up filtering when the maximum number of problem markers is\nreduced.\n- The problems view is no longer refreshed under selection changes when the\nfilter is disabled.\n- Filtering a resource delta containing M markers on a working set with W\nresources now runs in O((W + M) log W), improving the previous time bound of\nO(M^2 + MW).\n",
    "Created an attachment (id\u003d6723)\nThis should also improve performance slightly.\n\nWhen profiling the code, I noticed that a lot of runtime was spent resizing the\nArrayList in MarkerManager.buildMarkers... this patch changes the ArrayList\ninto a LinkedList, which should speed insertions for large lists.",
    "I tested the above patch by creating a workspace with over 8,000 errors (by\nimporting plugins and deleting their dependencies), then created a working set\ncontaining over 100 individual files (and no complete folders or projects). I\nthen timed how long it took to apply the filter.\n\nWithout the patch, my Eclipse install ran for over 10 minutes before I killed\nthe process. With the patch, the filter could be applied in less than 2 seconds.",
    "Created an attachment (id\u003d6724)\nIn case there\u0027s any problem applying the above patches, here\u0027s the full source\n",
    "Re: comment #11.  Did profiling show the linked list to be faster?  Since linked\nlist creates a new object for every insertion, and array list only creates a new\nobject when it grows, I\u0027m surprised this is faster overall.  Perhaps a more\naggressive growth function could be used for the array list to avoid the\noverhead of growing the list so often.",
    "FWIW, a data point, in my few large projects in my workspace, I have 46,694\nProblems, no compile errors. It does slow things down a bit ;-)",
    "Regardling LinkedList versus ArrayList:\n\nIf an ArrayList doubles in size every time it runs out of space, it will take\nO(n log n) time to make n insertions (since the array must be copied approx\nO(log n) times, and each copy takes O(n) time). A linked list takes constant\ntime for each insertion, to it takes O(n) time for n insertions, even though\nthere is a high hidden coefficient.\n\nThe Marker code was calling ensureCapacity before each set of insertions, which\nappears to be causing the ArrayList to grow by a constant factor each time\n(rather than doubling). This means that the array must be copied O(n) times\n(assuming that the markers are evenly distributed among resources), for an\noverall runtime of O(n^2).\n\nEven though individual insertions in a small linked list are massively slower\nthan an array, its asymptotic growth is lower so it will be much faster for\nlarge lists. My profiling showed a moderate improvement in the runtime after\nswitching to lists, but I was using statistical methods over a short time\nduration so the improvement could have been due to experimental error. I would\nencourage you to verify these findings yourself.\n",
    "Tsk tsk, someone\u0027s forgetting their complexity analysis \u003cg\u003e\n\nIt will grow log(n) times, but it will not copy O(n) elements each time.  Say it\nstarts with size\u003d1 and growth function is 2.  On the first growth it copies one\nelement, on the second growth it copies 2, then 4, etc up to n. This results in\nthe summation:\n\n1 + 2 + 4 + ... + n/4 + n/2 + n \u003c 2n\n\nThe result is O(n) complexity for insertion n elements (same as LinkedList).  If\nyou don\u0027t believe me, just read the javadoc for ArrayList:\n\n * The \u003ctt\u003esize\u003c/tt\u003e, \u003ctt\u003eisEmpty\u003c/tt\u003e, \u003ctt\u003eget\u003c/tt\u003e, \u003ctt\u003eset\u003c/tt\u003e,\n * \u003ctt\u003eiterator\u003c/tt\u003e, and \u003ctt\u003elistIterator\u003c/tt\u003e operations run in constant\n * time.  The \u003ctt\u003eadd\u003c/tt\u003e operation runs in \u003ci\u003eamortized constant time\u003c/i\u003e,\n * that is, adding n elements requires O(n) time.  All of the other operations\n * run in linear time (roughly speaking).  The constant factor is low compared\n * to that for the \u003ctt\u003eLinkedList\u003c/tt\u003e implementation.\u003cp\u003e\n\n\nYour second point about ensureCapacity is interesting though.  The class library\nimplementation I\u0027m using ensures that the growth function is still used when\nensureCapacity is used (it uses newSize \u003d Math.max(userSize, (oldSize * 3) /\n2)), but this might be different with another class library implementation I\nsuppose.\n\nI have benchmarks for this code so I\u0027ll play around with the growth function of\nthe list to see if it improves performance.",
    "I did some profiling on a larger test case (14,000 markers on 19,500 resources,\nrepeating the search 2000 times), calling findMarkers(DEPTH_INFINITE) on the\nworkspace root. With the current implementation it takes 32 milliseconds, and\nwith your patch it takes 47 milliseconds. In any case, at these speeds our\noptimization efforts are probably better directed elsewhere \u003cg\u003e (bug 44864 being\nmy favorite...)\n",
    "Created an attachment (id\u003d6739)\nSame patch, merged with HEAD on 2003/11/11\n",
    "Okay. Forget attachment 6723, then. The main performance hit is still fixed by\nattachment 6739.\n",
    "*** Bug 39621 has been marked as a duplicate of this bug. ***",
    "Created an attachment (id\u003d6753)\nFull source for the patch, merged with HEAD on 2003/11/11\n\nFor those of you having problems getting the last patch to apply, here\u0027s the\nfull source for the modified files.",
    "I\u0027m going to have to reject this patch.  I\u0027ve encountered two problems so far:\n1.) OutOfMemoryError when compiling after the patch (as opposed to before). \nAlso, the rebuilds take a lot longer (likely because of the OutOfMemoryError).\n2.) If I have a filter set to show 2000 items maximum, it displays 2000 items if\nthere are more than 2000 items actually.  Previously, if there were more, it\nwould display a message saying there were too many.\n\nI\u0027d imagine these two are related, but I\u0027m not sure.\n\nMy test environment is simply a standard platform-ui workspace.  platform-ui\nmodule from CVS, with everything else as binary projects.  I have very strict\ncompiler options (typically 20000+ warnings).  A rebuild is executed to test the\nproblem view.  Oh, and I\u0027m using GTK.\n\n(They also seem to disagree as to how many problems there are....  I\u0027m not sure\nabout that though.  I don\u0027t want to give any red herrings.)\n\nGiving this bug to Stefan, as he seems to be working on it now....",
    "Please give some steps to reproduce 1). This definitely needs fixing.\n\nRegarding \"show X items\" actually displaying X items rather than an error\nmessage: this seems like a bugfix, not a bug (I think MvM had comments about\nthis). However, this would mean your problems view tends to contain more\nentries. Perhaps differences in the GTK widgetry explain the performance\ndegradation?\n\nPlease provide more information for both problems: Exactly what filters were you\nusing, where did you notice the degradation (incremental builds, full builds,\nselection changes, or applying a new filter?)\n\nIf you could attach some sort of profiler data, it would really help me with the\nperformance problem.\n\nBTW, perhaps the OutOfMemoryError is a duplicate of bug 43351? This might not be\ndue to the patch.\n\n",
    "Doug and I investigated the performance issue. It looks like the limit on\ndisplayed errors is not always being applied, and during a build the problems\nview can contain all the markers in the workspace. Working on a fix.\n",
    "Created an attachment (id\u003d6827)\nPossible fix\n\nThis is a preliminary fix. It is not well tested, but I\u0027m including this early\nversion here for comment.\n\nIn addition to the previous patches:\n- The SWT Table is now updated incrementally in a background thread.\n- Once the marker limit is reached, the underlying SWT Table is cleared.\n- The view\u0027s content and its title are now updated by the same listener\n- The error message about exceeding the marker limit is back.\n",
    "Created an attachment (id\u003d6869)\nLatest patch\n\nLatest version of the patch. This still has a known bug (it munges up the\nnumbers of errors visible on the status bar and title of the problems view)...\nbut it should be sufficient for benchmarking.\n\nMy test cases:\n--------------\n\nAll tests done in a workspace containing 14,000 errors. \n- Times for \"rebuild all\" were similar with and without the patch (with all\ncombinations of filters). The same test ranged between 58-115s, so there was a\nhigh experimental error here.\n- Without the patch, Eclipse could not apply a working set filter with 100\ndistinct files (no folders or projects).\n- Selection changes in the package explorer were significantly faster with the\npatch. Using the \"selected resource and children\" filter, selection changes\ntook 6-12 seconds when selecting or deselecting a project with 12,000 errors.\nWith the patch, the same selection change consistently took less 300ms.\n",
    "Created an attachment (id\u003d6898)\nAll known issues fixed\n\nOkay. All known issues have been fixed. \n\nI have not been able to reproduce Doug\u0027s OutOfMemoryException. Doug, can you\nlet me know if this is still an issue? There is definitely still room for\nmemory optimization if it is.\n",
    "Created an attachment (id\u003d6990)\nLatest patch, following suggestions from Tod\n",
    "The latest patch adds the following:\n- Marker searches and filtering is done in in a background thread (although this\nnow takes less than 400ms in a workspace with 30,000 markers).\n- Threading is done using the Jobs API.\n- Various changes have been made to the marker views and their actions to reduce\n concurrency issues.\n- ITableViewContentProvider and MarkerRegistry are gone.\n- Rather than adding and removing markers based on the contents of resource\ndeltas, the entire view is invalidated when a resource changes. This eliminates\nstale marker bugs, and does not seriously impact performance since filtering is\nnow very fast.\n\n",
    "\u003e- Rather than adding and removing markers based on the contents of resource\n\u003edeltas, the entire view is invalidated when a resource changes. This eliminates\n\u003estale marker bugs\n\nIt seems really wasteful not to make use of the marker deltas generated by core.\nAre you saying that you\u0027ll refresh the entire view when any resource changes? \nIs this based on a belief that stale marker bugs are caused by incorrect marker\ndeltas? If so it needs to be investigated in core, otherwise other clients of\nmarker deltas will have similar problems.\n\nNote there is a method IResourceChangeEvent.findMarkerDeltas that produces a\nlist of marker changes for you without even having to traverse the delta. ",
    "When the search is occurring in a background thread and takes less than 300ms\n(even in extreme cases), there is no point in maintaining the large amount of\ncode that tried to optimize this further by keeping track of deltas. Prior to\nthe patch, filtering was slow and happened in the UI thread. Neither of these\nare the case anymore.\n\nThe bottleneck isn\u0027t in the marker search or filtering. The bottleneck is now in\nTable and TableViewer.\n",
    "This patch is still not ready to go\n\n1) There are a lot of compiler warnings, including some unused imports which \nget flagged by the builder. Please tidy these up\n\n2) I get two Searching for Markers jobs which never move pat 0% progress\n\n3) When the table updates I get chunks of it dissappearing a time leaving \nseveral blank entries in the table for the duration of the operation.\n\nI\u0027ll attach a new patch done against HEAD to save the pain of integration",
    "Created an attachment (id\u003d6999)\nProgress View screenshot showing missing lines\n",
    "Created an attachment (id\u003d7000)\nPatch applied against current HEAD\n",
    "If an incremental compile generates a few new problems (or fixes a few), the \nProblems view should not have to be fully refreshed.  This will consume more \ncycles (even if done in a background thread), and will result in more UI \nflicker than just processing the delta.  \n\nI strongly suggest leaving the delta processing in.",
    "There was also the following walkback in the log.\n\nThe steps are\n\n1) Createa new workbench\n2) Load platform-ui module\n3) Load it again\n\n!STACK 0\njava.lang.IndexOutOfBoundsException: Index: 1, Size: 1\n\tat java.util.ArrayList.RangeCheck(ArrayList.java:507)\n\tat java.util.ArrayList.get(ArrayList.java:324)\n\tat java.util.Collections$SynchronizedList.get(Collections.java:1786)\n\tat org.eclipse.core.internal.jobs.JobListeners$7.run\n(JobListeners.java:111)\n\tat org.eclipse.core.internal.runtime.InternalPlatform.run\n(InternalPlatform.java:1127)\n\tat org.eclipse.core.runtime.Platform.run(Platform.java:464)\n\tat org.eclipse.core.internal.jobs.JobListeners.doNotify\n(JobListeners.java:86)\n\tat org.eclipse.core.internal.jobs.JobListeners.done\n(JobListeners.java:135)\n\tat org.eclipse.core.internal.jobs.JobManager.endJob\n(JobManager.java:283)\n\tat org.eclipse.core.internal.jobs.WorkerPool.endJob\n(WorkerPool.java:120)\n\tat org.eclipse.core.internal.jobs.Worker.run(Worker.java:72)",
    "I must have been unclear. Updating the table widget (ie: the slow part, and the\npart that causes flicker) is still incremental. Filtering and searching are no\nlonger incremental. These are not the same thing.\n\nFOR EXAMPLE:\n\n1. A delta arrives.\n2. The view is invalidated. \n3. Pending updates to the problems view are cancelled (see steps 9 and 10).\n4. A background job is scheduled to search for markers.\n5. The search job blocks until the workspace has stablized.\n6. The entire workspace is searched for new markers.\n7. Three new markers are discovered that are not currently visible in the\nproblems view.\n8. The three new markers are added to a queue of changes to the table view.\n9. A update job is created to incrementally apply the pending changes, and the\nsearch job terminates.\n10. When the update job wakes up, it discovers the 3 new markers in its queue\nand adds them to the table without changing the rest of the table contents. If\nthere are too many other changes pending for the table widget, the job sleeps\nand step 10 repeats until the table is up-to-date.\n\nThe part that is no longer incremental is the bit in step 6. The bit that needs\nto be incremental to reduce flicker orrurs in step 10. \n\n\nWHY REMOVE INCREMENTAL SEARCHING:\n\nEliminating incremental searching means that resource changes, selection changes\n(in the package explorer), and filter changes can all share the same code.\nOtherwise, they all need their own algorithms for determining the set of markers\nthat have been added or removed since the last search. True, the searches\nthemselves aren\u0027t too complex, but these things all happen in different threads\nand keeping them in synch is messy.... and even if you get it right, the best\nyou can do is save 300ms in a background thread that runs once per build.\n\nIf you disagree with me about the CPU cost or how frequently it occurs, I\nencourage you to profile MarkerFilter.findMarkers, which is where all searching\nand filtering occurs. \n\n\nREGARDING FLICKER:\n\nYes, there IS more flicker. This has nothing to do with searching or filtering\n-- it is because of the new update job (steps 9 and 10). Without the patch, all\nchanges to the table widget are applied at once (ie: you can -- and will -- have\nincrements of over 20,000 markers). This causes Eclipse to completely lock up\nuntil the table is sorted and refreshed, which can take over 10 seconds. \n\nWith certain filters (ie: \"selected resource\", \"selected resource and children\",\nand \"anything in the same project\"), the visible markers change drastically each\ntime you click on the package explorer or a new editor... and 10 second lag per\nmouseclick is virtually unusable.\n\nWith the patch, this is split up into many increments of about 100ms each. This\nlets you continue using Eclipse while the updates occur, although it necessarily\ncreates flicker while the table updates. The choice is: either you can\u0027t use\nEclipse at all for about 10 seconds or you live with a flickery problems view\nfor about 40 seconds.\n\nIf we could improve the insertion and removal times for TableViewer and Table,\nthen the changes could be applied in larger increments and the flicker would no\nlonger be noticable. \n",
    "Regarding comment 37\n\n1) Will fix.\n\n2) This is not a problem. The tasks view and the problems view each has its own\n\"searching for markers\" job. If there is a build running, the search jobs wait\nfor the build to finish and will not progress beyond 0%. Once the build is\nfinished, and the actual search and filtering usually happens too quickly to see\nany change in the progress monitor. \n\nTo eliminate confusion, I will change the description to indicate which view is\nassociated with which job, and add a subtask to explain that the marker search\nis waiting for another operation to complete.\n\n3) Attempting to reproduce.\n",
    "Re: comment 36, it\u0027s not a matter of leaving the delta processing in -- it\u0027s a\nmatter of rewriting the delta processing so that it is multithread-friendly.",
    "The problem in comment 37 does not appear related to this patch (or the problem\nit fixes). This should probably be filed as a new bug.",
    "Created an attachment (id\u003d7007)\nLet\u0027s try again\n\nThis adds some additional progress messages so that people don\u0027t misinterpret\nthe 0% progress bar as a bug.\n\nAlso fixes a bug discovered by Tod that occasionally prevents the marker count\nfrom being invalidated.",
    "Re: comment #38\n\n6. The entire workspace is searched for new markers.\n7. Three new markers are discovered that are not currently visible in the\nproblems view.\n\nTo discover that there are three *new* markers, don\u0027t you have to manually\ncompute a delta of your own?  I.e, you can search the workspace and obtain a\nlist of all existing markers, but then to figure out if any of these are new\ndon\u0027t you need to compare that complete set against the marker view contents? \nAll this to compute the information obtained by\nIResourceChangeEvent.findMarkerDeltas...",
    "The walkback in comment #37 is a dup of core bug 46883.",
    "Re: comment 43\n\nI fear I\u0027ve made a mistake by initiating a discussion by posting a simplified\nsummary of the patch. I appologise for the unnecessary traffic. It seems that\nanything less than the source code itself is open to ambiguity and misunderstanding.\n\nThe important parts are:\n- Working set filters are faster (measured improvements of over 1000 times).\n- Selection changes are significantly faster for selection-sensitive filters\n(measured improvements of over 20 times)\n- bug 39436 is fixed\n- Builds are slightly faster (by up to 10%)\n- The most intensive computations have been moved out of the UI thread or broken\nup into increments.\n\nThese can be easily measured and verified. \n\nIt is still possible to improve performance further by any number of additional\noptimizations (including examining resource deltas), but these not necessary to\nfix this bug.\n\nIf there is a case where this patch degrades performance, creates additional\nbugs, or fails to fix the problem originally reported here, please report it\nhere. If anyone is curious about implementation details, I will be happy to\ndiscuss it via e-mail.",
    "After discussions with Nick and John:\n\nRequirements:\n- Code for processing change deltas will be added. It seems that the empty\nproblems view (comment 34) was occurring prior to the patch, but it may have\nbeen related to the processing of change deltas. \n- A more efficient variant of the IContainmentAdapter code will be folded back\nin. The JDT requires the use of IContainmentAdapter for its working sets. \n- The flickering problems view will be fixed before this gets merged with head.\n\nSuggestions:\n- Flag uninteresting jobs as \"system\"\n- Use scheduling rules to prevent the 0% progress meters from appearing until\nthey are ready to proceed.\n- Ignore resource deltas that do not contain marker changes.\n\n\n",
    "Not sure if the old code used IContainmentAdapter for the other filtering modes \nthat track selection, but it should.  For example, if I select package a, it \nshould show only the problems in compilation units in package a (or the package \nitself), and should not should problems in package a.b.\n",
    "If the old code didn\u0027t use IContainmentAdapter, then I strongly recommend that\nwe do not begin using it now. \n\nIContainmentAdapter is the main reason why Working Set filters are so slow. It\ntakes over 10 minutes (and often over 30 minutes), to apply an\nIContainmentAdapter-based filter to 15,000 markers with a working set of size\n100. This is not reasonable.\n\nIf we\u0027re planning on adding a new feature to support working sets on the logical\n(as well as physical) structure, we need something more powerful than\nIContainmentAdapter.\n\nHere are two possible solutions:\n\nSolution 1:\n-----------\nProvide the power to traverse the children of an object supporting\nIContainmentAdapter. In this case, a single DFS can be used to build a more\nefficient search structure that could be used for subsequent lookups.\n\nRather than IContainmentAdapter, use something like this:\n\ninterface ITreeAdapter {\n  Object[] getChildren();\n  Object getParent();\n  boolean contains(Object element);\n}\n\nIt might be possible to reuse existing TreeContentProviders for this purpose\n\nSolution 2:\n-----------\n\nAdd a \"contains(...)\" method to IWorkingSet. In this case, specialized working\nsets could implement more efficient searches internally.\n\nSolution 3:\n-----------\n\nBack out of our support for IContainmentAdapter on working sets, and redefine\n\"working set\" to refer specifically to physical structure. Since the current\nworking sets are effectively unusable, we lose nothing by changing their\nsemantics slightly.\n\n\nNote that the current patch uses solution 3, which reduces the filtering time\nfrom over 10 minutes to a few milliseconds. \n\n",
    "Note: I am currently updating the patch to make use of IContainmentAdapter. \n\nIn order to make this run in a reasonable amount of time, I am making the\nassumption that an IResource can only be in the working set if it has a physical\nparent in the working set. \n\nThis assumption may not always be correct and filtering will still be many times\nslower than it is with the current patch. To be completely clear: we cannot\ncontinue to use IContainmentAdapter in its current form to determine containment\nin a working set.\n",
    "Solution 1: I believe this is one approach we tried before we came up with \nIContainmentAdapter.  The problem here is that it can be used to efficiently \ndetermine the initial set of markers to display, but it can\u0027t be used for \ntesting containment after initial population (e.g. when a new marker comes \nalong).  There\u0027s also no notification for when resources change under an \nelement in the working set.\n\nSolution 2: There is only one implementation of IWorkingSet.  A Java working \nset is not really a different kind of working set, it just has different kinds \nof elements (Java elements instead of resources).\n\nSolution 3: I disagree that we lose nothing.  Users find it really confusing \nwhen problems from subpackages are shown when they didn\u0027t ask for them.  We had \nrecurring PRs against earlier versions of Eclipse because of this problem.  \nWhile it\u0027s true that the worst-case performance for working set filtering is \nabysmal, in practice you don\u0027t see this in typical manually-created working \nsets.  I\u0027m not tied to the current solution using IContainmentAdapter.  If we \ncan come up with a better mechanism to solve the problem, then great.  However, \nI think it\u0027s important that we not lose the ability to filter markers by \npackage, and as mentioned in comment #47, this should also work for regular \nselection-based filtering.  Let\u0027s see how bad the performance is with your new \npatch (following the approach we discussed yesterday) then re-evaluate.\n\n",
    "Regarding solution 1:\n\nThis can be used to determine containment when new markers arrive. Here\u0027s how: \n\n1. Put every resource in the working set into a HashSet. Use the getChildren()\nmethods to perform a DFS on every element in the working set. Do not search the\ncontents of non-IResource elements. Insert the path to every IResource touched\nby the DFS into a HashSet called C.\n\n2. To test if a particular marker passes the filter, determine if the path to\nits resource is in C.\n\n3. Every time a resource change event occurs or the user explicitly changes\ntheir working set, invalidate C (and regenerate it the next time we test a marker).\n\nNote that generating the cache C in step 1 is the slowest part. However, step 1\nis still faster than a single IContainmentAdapter test right now since it only\ntraverses IResources and not the entire Java model. The cache is reused for\nmultiple marker tests.\n\nThe working set itself doesn\u0027t need to send notifications when its resources\nchange. The algorithm can be run in the viewer, which can attach a regular\nResourceChangeListener to the workspace so that it knows when to invalidate the\ncache.\n\nAlgorithm Runtime:\n\nLet \n W \u003d resources in working set\n R \u003d resources directly or indirectly included in the working set\n J \u003d number of nodes in the java model in the R resources\n M \u003d number of markers to be filtered\n\nWhere W \u003c R \u003c M\n \nAssuming a pessimistic O(lg n) insertion and containment test time for HashSet,\nthe algorithm will run in:\n\nO((R+M) lg R)\n\nAssuming O(1) HashSet operations, we get:\n\nO(R+M)\n\nIn contrast, the current algorithm runs in O(JM)\n\nThe worst case for the proposed algorithm would occur if a resource change event\noccurs between each marker test, in which case the algorithm takes O(RM) time\nfor M marker tests. However, this is still better than the current runtime since\nR is much smaller than J. The typical case would closely resemble the best case,\nsince there is usually only one resource change per refresh of the problem view.\n\n",
    "*** Bug 47902 has been marked as a duplicate of this bug. ***",
    "In Eclipse 3.0M5 filtering tasks is *much* slower than filtering in Eclipse \n2.1.1. (Probably two orders on magnitude slower.) I\u0027m using Windows XP.",
    "Created an attachment (id\u003d7090)\nLatest patch with sorting optimizations\n\nThis version of the patch adds:\n- Sorting is now done incrementally in a background thread\n- When applying the marker limit, the problems view now shows the top markers\n(according to the current sort criteria) instead of an error message. This\nmakes the problem view usable with very low marker limits, resulting in\nsignificantly better refresh times.\n- The default marker limit has been changed from 2000 to 300.\n- There is no more flicker when populating the marker views\n- Markers are inserted at the end of the TableViewer whenever possible, to take\nadvantage of the best-case Table insertion times.\n- Redraw is disabled while populating the table widgets.\n- Resource deltas are now examined. Deltas containing no marker additions or\nremovals can now be processed without refreshing the view.\n- Marker comparisons are now approximately 5 times faster (the view now caches\nmarker data in a form efficient for comparisons).\n- Much of the threading code has been rewritten to reduce the probability of\nthe UI waiting on mutexes, and to allow long-running background operations to\nbe interrupted safely.\n- The average amount of processing per update in the UI thread has been reduced\nfrom (approx) 200ms to 50ms.\n\nNote: this code appears to work correctly with the Dec 3 integration build, but\nI have not been able to get the code in HEAD on Dec 8 to launch correctly. If\nanyone has their workspace in a stable state, could you please investigate if\nthis can go into tomorrow\u0027s build?\n",
    "Note: The current patch still does not use IContainmentAdapter for working sets.\nThe performance degradation for IContainmentAdapter-based filtering is still too\nsevere.",
    "I have released the current patch - inital testing is looking good (and fast!) \nand it looks like the dead marker problem has also been solved - excellent \nwork Stefan. The only prpblem I found was that I lost selection when I changed \nsort order.\n\nI\u0027ll leave the PR open until you have fixed all of the issues you wanted to \nlook at.",
    "I believe the problem described in this PR is fixed. I will open new PRs for any\nproblems caused by the patch.\n\nPlease reopen if the performance degradation is still a problem.",
    "Verified in I200312160800.\n",
    "*** Bug 28162 has been marked as a duplicate of this bug. ***",
    "*** Bug 40822 has been marked as a duplicate of this bug. ***"
  ],
  "commentCreationDates": [
    "2003-10-08T16:35:37+02:00",
    "2003-10-09T22:30:01+02:00",
    "2003-10-10T00:18:36+02:00",
    "2003-10-10T03:18:47+02:00",
    "2003-10-10T17:45:06+02:00",
    "2003-10-14T17:03:58+02:00",
    "2003-10-15T18:46:51+02:00",
    "2003-10-20T22:30:14+02:00",
    "2003-10-29T15:56:44+01:00",
    "2003-11-05T16:09:08+01:00",
    "2003-11-11T04:04:56+01:00",
    "2003-11-11T04:08:54+01:00",
    "2003-11-11T04:29:25+01:00",
    "2003-11-11T04:50:20+01:00",
    "2003-11-11T15:11:31+01:00",
    "2003-11-11T18:19:45+01:00",
    "2003-11-11T21:13:47+01:00",
    "2003-11-11T22:45:30+01:00",
    "2003-11-11T23:53:25+01:00",
    "2003-11-12T01:03:06+01:00",
    "2003-11-12T01:19:38+01:00",
    "2003-11-12T05:57:42+01:00",
    "2003-11-12T18:05:07+01:00",
    "2003-11-12T22:19:33+01:00",
    "2003-11-13T20:59:04+01:00",
    "2003-11-13T22:02:29+01:00",
    "2003-11-18T06:38:50+01:00",
    "2003-11-19T17:51:15+01:00",
    "2003-11-21T01:26:10+01:00",
    "2003-11-27T21:58:09+01:00",
    "2003-11-27T22:42:14+01:00",
    "2003-11-27T23:17:21+01:00",
    "2003-11-28T00:22:02+01:00",
    "2003-11-28T14:08:52+01:00",
    "2003-11-28T14:12:17+01:00",
    "2003-11-28T14:14:58+01:00",
    "2003-11-28T14:15:55+01:00",
    "2003-11-28T14:16:43+01:00",
    "2003-11-28T18:08:44+01:00",
    "2003-11-28T20:07:20+01:00",
    "2003-11-28T22:22:15+01:00",
    "2003-11-29T01:32:03+01:00",
    "2003-11-29T01:35:56+01:00",
    "2003-12-01T15:02:12+01:00",
    "2003-12-01T15:59:33+01:00",
    "2003-12-01T16:39:40+01:00",
    "2003-12-01T22:59:52+01:00",
    "2003-12-02T16:30:52+01:00",
    "2003-12-02T17:12:36+01:00",
    "2003-12-02T17:20:22+01:00",
    "2003-12-02T17:46:28+01:00",
    "2003-12-02T19:28:26+01:00",
    "2003-12-02T20:16:30+01:00",
    "2003-12-04T04:09:12+01:00",
    "2003-12-09T06:06:25+01:00",
    "2003-12-09T06:19:54+01:00",
    "2003-12-09T14:25:14+01:00",
    "2003-12-09T20:40:21+01:00",
    "2003-12-16T20:08:15+01:00",
    "2004-02-26T05:55:11+01:00",
    "2004-09-23T20:55:00+02:00"
  ],
  "traces": [
    {
      "exceptionType": "java.lang.IndexOutOfBoundsException",
      "message": "Index: 1, Size: 1",
      "elements": [
        {
          "method": "java.util.ArrayList.RangeCheck",
          "source": "ArrayList.java:507"
        },
        {
          "method": "java.util.ArrayList.get",
          "source": "ArrayList.java:324"
        },
        {
          "method": "java.util.Collections$SynchronizedList.get",
          "source": "Collections.java:1786"
        },
        {
          "method": "org.eclipse.core.internal.jobs.JobListeners$7.run",
          "source": "JobListeners.java:111"
        },
        {
          "method": "org.eclipse.core.internal.runtime.InternalPlatform.run",
          "source": "InternalPlatform.java:1127"
        },
        {
          "method": "org.eclipse.core.runtime.Platform.run",
          "source": "Platform.java:464"
        },
        {
          "method": "org.eclipse.core.internal.jobs.JobListeners.doNotify",
          "source": "JobListeners.java:86"
        },
        {
          "method": "org.eclipse.core.internal.jobs.JobListeners.done",
          "source": "JobListeners.java:135"
        },
        {
          "method": "org.eclipse.core.internal.jobs.JobManager.endJob",
          "source": "JobManager.java:283"
        },
        {
          "method": "org.eclipse.core.internal.jobs.WorkerPool.endJob",
          "source": "WorkerPool.java:120"
        },
        {
          "method": "org.eclipse.core.internal.jobs.Worker.run",
          "source": "Worker.java:72"
        }
      ],
      "number": 0,
      "commentIndex": 37,
      "bugId": "44443",
      "date": "2003-11-28T14:16:43+01:00",
      "product": "Platform",
      "component": "UI",
      "severity": "normal"
    }
  ],
  "groupId": "44443",
  "bugId": "44443",
  "date": "2003-10-08T16:35:37+02:00",
  "product": "Platform",
  "component": "UI",
  "severity": "normal"
}